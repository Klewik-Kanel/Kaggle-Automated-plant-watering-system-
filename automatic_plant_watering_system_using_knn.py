# -*- coding: utf-8 -*-
"""Automatic Plant watering System using KNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/klewikkanel/automatic-plant-watering-system-using-knn.30e402c7-c46d-46e2-b1dc-22d8af591192.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250427/auto/storage/goog4_request%26X-Goog-Date%3D20250427T142356Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4cecdcbaf1ea63d8ffd0c9ec3df89840a0de262bfbd6aa547d6ed15ee54e4f85605dd1f619c7eeac143cc373ecdfa022b7d6b5d745ae55eac5dfa841d4c06d325bc5bd2e023300bc6f09d9d8be8fffcdbdf11f62565336478791e18bb820b007e7e0d7fbc9d6731ab14d372f80ee7f8ddaa8785e225fd67c91cf2d5f06f0c3f7279dff49629a2a8a1b50ba0ebfab7e0e5ac3327c56e1ff4a2e4ef8304e05cbef6d05abd204a4ab62a2349a72e764822443ec6e641f0be0710cb59c778ff9fb157ad748fc494fd5afa0055a2b4ba688d21c1907dff2b9cb4bc3e54b5427799286d38a8fc7139e3503587d54889897ba9d45a1373e5633940dc8263f42268c9eed
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
  import kagglehub
  nelakurthisudheer_dataset_for_predicting_watering_the_plants_path = kagglehub.dataset_download('nelakurthisudheer/dataset-for-predicting-watering-the-plants')

  print('Data source import complete.')

  import warnings
  warnings.filterwarnings("ignore")
  import numpy as np
  import pandas as pd
  from sklearn.preprocessing import LabelBinarizer
  from sklearn.experimental import enable_iterative_imputer
  from sklearn.impute import IterativeImputer
  from sklearn.preprocessing import StandardScaler
  import seaborn as sns
  import matplotlib.pyplot as plt
  from statsmodels.stats.outliers_influence import variance_inflation_factor
  from sklearn.model_selection import train_test_split
  from sklearn.experimental import enable_halving_search_cv
  from sklearn.model_selection import HalvingGridSearchCV, KFold, cross_val_predict
  from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score

  df = pd.read_csv('/kaggle/input/dataset-for-predicting-watering-the-plants/TARP.csv')
  df.head()

  encoder = LabelBinarizer()
  df['Status'] = encoder.fit_transform(df['Status'])
  df.info()

  df.describe().T

  imputer = IterativeImputer(random_state=46, verbose=True)
  data = imputer.fit_transform(df)
  data = pd.DataFrame(data, columns = df.columns)
  data.head()

  import seaborn as sns
  plt.figure(figsize=(20,20))
  corr = df.corr()
  sns.heatmap(corr,annot=True)

  #scaling the data
  from sklearn.preprocessing import MinMaxScaler

  scaler = MinMaxScaler((-1,1))
  sdf = scaler.fit_transform(data.iloc[:,:-1], data.iloc[:,-1])
  scaled_df = pd.DataFrame(sdf, columns = data.iloc[:,:-1].columns)
  scaled_df['Status'] = data['Status']
  scaled_df.head()

  def distplots(col):
    sns.distplot(df[col])
    plt.show()

  for i in list(df.columns)[:-1]:
    distplots(i)

  g = sns.clustermap(scaled_df.corr(),
                    method = 'complete',
                    cmap   = 'RdBu',
                    annot  = True,
                    annot_kws = {'size': 8})
  plt.setp(g.ax_heatmap.get_xticklabels(), rotation=60);

  plt.hist(scaled_df['Status'])
  plt.show()

  """*SVM*"""

  x = scaled_df.iloc[:,:-1]
  y = scaled_df.iloc[:,-1]

  #scaling the data
  scaler = MinMaxScaler((-1,1))
  #scaler = StandardScaler()
  x=scaler.fit_transform(x)
  y = y

  x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.3, random_state=7)

  # Apply KNN
  from sklearn.neighbors import KNeighborsClassifier
  model_knn3 = KNeighborsClassifier(n_neighbors=3)
  knn = model_knn3.fit(x_train, y_train)
  # Predicting Test Set N=3
  y_pred = model_knn3.predict(x_test)
  #Accuracy
  accuracy_KNN = accuracy_score (y_test, y_pred)
  print(f'Accuracy: {accuracy_KNN * 100:.2f}%')

  from sklearn.metrics import classification_report
  print(classification_report(y_test, y_pred))

  cm = confusion_matrix(y_test, y_pred)

  # Display the confusion matrix using seaborn
  sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
  plt.xlabel("Predicted Label")
  plt.ylabel("True Label")
  plt.title("Confusion Matrix")
  plt.show()

  input_data = (5,23,27,4,21.44,5.8,28.38,22.67,101.46,7.375482851,224.0581164,98,47,37)

  input_data_as_array = np.asarray(input_data)
  input_data_reshaped = input_data_as_array.reshape(1,-1)
  std_data = scaler.transform(input_data_reshaped)

  prediction = model_knn3.predict(std_data)
  print(prediction)